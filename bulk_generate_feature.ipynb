{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 84,
            "id": "bd13a62c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.cluster import KMeans\n",
                "from tqdm import tqdm\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib as joblib\n",
                "import csv\n",
                "from sklearn.metrics import silhouette_score\n",
                "from services.database import ClusterFeatureDatabaseService"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "id": "dec5b4f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def dataLoader(path):\n",
                "    data = pd.read_csv(path,encoding = \"ISO-8859-1\")\n",
                "    return data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "id": "047dcc8e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def describe_cluster(words_list,model):\n",
                "    labels=model.labels_\n",
                "    clusters=pd.DataFrame(list(zip(words_list,labels)),columns=['title','cluster'])\n",
                "    u_labels =  np.array(np.unique(labels), dtype=object)\n",
                "    pd.options.display.max_rows = 4000   \n",
                "    for i in u_labels:\n",
                "      print(i)\n",
                "      print(clusters.loc[clusters['cluster'] == i])\n",
                "      print('\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "id": "c08f8efc",
            "metadata": {},
            "outputs": [],
            "source": [
                "def cluster_text(text,k):\n",
                "    vectorizer = TfidfVectorizer(stop_words={'english'})\n",
                "    X = vectorizer.fit_transform(text)\n",
                "    model = KMeans(n_clusters=k, init='k-means++', max_iter=200, n_init=10)\n",
                "    model.fit(X)\n",
                "    joblib.dump(model, 'model.pkl')\n",
                "    score = silhouette_score(X, model.labels_, metric='euclidean')\n",
                "    print(\"Silhouette score: {:.2f}\".format(score))\n",
                "    joblib.dump(vectorizer, 'vectorizer.pkl')\n",
                "    # describe_cluster(text,model)\n",
                "    \n",
                "    return model\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "id": "1aeeb57c",
            "metadata": {},
            "outputs": [],
            "source": [
                "arrayOfWords=[];\n",
                "def groupDataSet(df):\n",
                "    df.fillna('', inplace=True)\n",
                "    df = df.reset_index()  # make sure indexes pair with number of rows\n",
                "  \n",
                "    for index, row in tqdm(df.iterrows(),bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}',total=len(df)):\n",
                "       # add the feature to the array if it has not been added yet case insensitive\n",
                "         if row['feature'] not in arrayOfWords:\n",
                "            arrayOfWords.append(row['feature'])\n",
                "            # 1132\n",
                "    return cluster_text(arrayOfWords,1132);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "id": "8c346301",
            "metadata": {},
            "outputs": [],
            "source": [
                "def predictCluster(text:str):\n",
                "    # load the model from disk\n",
                "    model = joblib.load('model.pkl')\n",
                "    # make predictions on the text\n",
                "    vectorizer = TfidfVectorizer(stop_words={'english'})\n",
                "    # predict clust of text using the model\n",
                "    X = vectorizer.fit_transform([text])\n",
                "    return model.predict(X)\n",
                "    \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "id": "0e31004f",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 95281/95281 [00:04<00:00, 19295.42it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Silhouette score: 0.11\n"
                    ]
                }
            ],
            "source": [
                "data=dataLoader(\"data/final_features.csv\")\n",
                "data.head()\n",
                "model=groupDataSet(data)\n",
                "# data=predictCluster(\"Head\")\n",
                "# print(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "id": "f4bc0ac5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# def write_to_csv(datas, path):\n",
                "#     with open(path, 'w') as f:\n",
                "#         writer = csv.writer(f)\n",
                "#         for i in range(0,len(datas)):\n",
                "#             data=datas[i]\n",
                "#             writer.writerow([i,','.join(data)])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "id": "2a88c830",
            "metadata": {},
            "outputs": [],
            "source": [
                "# out = []\n",
                "# for i in range(0,max(model.labels_)+1):\n",
                "#     out.append([])\n",
                "\n",
                "# for i in range(0,len(arrayOfWords)):\n",
                "#     out[model.labels_[i]].append(arrayOfWords[i])\n",
                "# for i in range(0,len(out)):\n",
                "#     for word in out[i]:\n",
                "#         ClusterFeatureDatabaseService().put({\n",
                "#             \"cluster\":i,\n",
                "#             \"feature\":word,\n",
                "#             },\n",
                "#         )\n",
                "\n",
                "# print(out)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d85a7779",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "id": "35b6ecf4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Unexpected exception formatting exception. Falling back to standard exception\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Traceback (most recent call last):\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
                        "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
                        "  File \"/var/folders/x3/zv1948355lj7wtrfgg3vbmfr0000gn/T/ipykernel_96390/2615851966.py\", line 1, in <cell line: 1>\n",
                        "    cfs = ClusterFeatureDatabaseService().get_all()\n",
                        "  File \"/Users/habib/Desktop/aait/ultimate_feed_nlp/util/Singleton.py\", line 6, in __call__\n",
                        "    cls._instances[cls] = super(\n",
                        "  File \"/Users/habib/Desktop/aait/ultimate_feed_nlp/services/database.py\", line 49, in __init__\n",
                        "  File \"/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/os.py\", line 675, in __getitem__\n",
                        "    raise KeyError(key) from None\n",
                        "KeyError: 'DB_CLUSTER_FEATURE_LOC'\n",
                        "\n",
                        "During handling of the above exception, another exception occurred:\n",
                        "\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/IPython/core/interactiveshell.py\", line 1982, in showtraceback\n",
                        "    stb = self.InteractiveTB.structured_traceback(\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
                        "    return FormattedTB.structured_traceback(\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
                        "    return VerboseTB.structured_traceback(\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
                        "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
                        "    frames.append(self.format_record(r))\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
                        "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
                        "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/stack_data/core.py\", line 698, in lines\n",
                        "    pieces = self.included_pieces\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
                        "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
                        "    pos = scope_pieces.index(self.executing_piece)\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
                        "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
                        "    return only(\n",
                        "  File \"/Users/habib/Library/Python/3.8/lib/python/site-packages/executing/executing.py\", line 164, in only\n",
                        "    raise NotOneValueFound('Expected one value, found 0')\n",
                        "executing.executing.NotOneValueFound: Expected one value, found 0\n"
                    ]
                }
            ],
            "source": [
                "cfs = ClusterFeatureDatabaseService().get_all()\n",
                "for cf in cfs:\n",
                "    print(cf)\n",
                "    print(cf['cluster'],cf['feature']) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "id": "2be694fe",
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'cfs' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m/Users/habib/Desktop/aait/ultimate_feed_nlp/bulk_generate_feature.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/bulk_generate_feature.ipynb#ch0000011?line=0'>1</a>\u001b[0m cfs[\u001b[39m0\u001b[39m]\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'cfs' is not defined"
                    ]
                }
            ],
            "source": [
                "cfs[0]"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        },
        "kernelspec": {
            "display_name": "Python 3.8.9 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.9"
        },
        "vscode": {
            "interpreter": {
                "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
