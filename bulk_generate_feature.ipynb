{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd13a62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib as joblib\n",
    "import csv\n",
    "from sklearn.metrics import silhouette_score\n",
    "from services.database import ClusterFeatureDatabaseService\n",
    "\n",
    "x=None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dec5b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataLoader(path):\n",
    "    data = pd.read_csv(path,encoding = \"ISO-8859-1\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "047dcc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_cluster(words_list,model):\n",
    "    labels=model.labels_\n",
    "    clusters=pd.DataFrame(list(zip(words_list,labels)),columns=['title','cluster'])\n",
    "    u_labels =  np.array(np.unique(labels), dtype=object)\n",
    "    pd.options.display.max_rows = 4000   \n",
    "    for i in u_labels:\n",
    "      print(i)\n",
    "      print(clusters.loc[clusters['cluster'] == i])\n",
    "      print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c08f8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_text(text,k):\n",
    "    vectorizer = TfidfVectorizer(stop_words={'english'})\n",
    "    X = vectorizer.fit_transform(text)\n",
    "    print(len(text))\n",
    "    print(X.shape)\n",
    "    x=X;\n",
    "    model = KMeans(n_clusters=k, init='k-means++', max_iter=200, n_init=10)\n",
    "    model.fit(X)\n",
    "    joblib.dump(model, 'model.pkl')\n",
    "    score = silhouette_score(X, model.labels_, metric='euclidean')\n",
    "    print(\"Silhouette score: {:.2f}\".format(score))\n",
    "    # describe_cluster(text,model)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1aeeb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayOfWords=[];\n",
    "def groupDataSet(df):\n",
    "    df.fillna('', inplace=True)\n",
    "    df = df.reset_index()  # make sure indexes pair with number of rows\n",
    "  \n",
    "    for index, row in tqdm(df.iterrows(),bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}',total=len(df)):\n",
    "       # add the feature to the array if it has not been added yet case insensitive\n",
    "         if row['feature'] not in arrayOfWords:\n",
    "            arrayOfWords.append(row['feature'])\n",
    "            # 1132\n",
    "    return cluster_text(arrayOfWords,1132);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c346301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e31004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95281/95281 [00:04<00:00, 20055.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671\n",
      "(3671, 3442)\n",
      "Silhouette score: 0.11\n"
     ]
    }
   ],
   "source": [
    "data=dataLoader(\"data/final_features.csv\")\n",
    "data.head()\n",
    "model=groupDataSet(data)\n",
    "# data=predictCluster(\"Head\")\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4bc0ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(datas, path):\n",
    "    with open(path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for i in range(0,len(datas)):\n",
    "            data=datas[i]\n",
    "            writer.writerow([i,','.join(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a88c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = []\n",
    "# for i in range(0,max(model.labels_)+1):\n",
    "#     out.append([])\n",
    "\n",
    "# for i in range(0,len(arrayOfWords)):\n",
    "#     out[model.labels_[i]].append(arrayOfWords[i])\n",
    "# for i in range(0,len(out)):\n",
    "#     for word in out[i]:\n",
    "#         ClusterFeatureDatabaseService().put({\n",
    "#             \"cluster\":i,\n",
    "#             \"feature\":word,\n",
    "#             },\n",
    "#         )\n",
    "\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85a7779",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35b6ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfs = ClusterFeatureDatabaseService().get_all()\n",
    "# for cf in cfs:\n",
    "#     print(cf.cluster,cf.feature) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2be694fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95281/95281 [00:04<00:00, 20434.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3671\n",
      "(3671, 3442)\n",
      "Silhouette score: 0.10\n"
     ]
    }
   ],
   "source": [
    "df=dataLoader(\"data/final_features.csv\")\n",
    "df.fillna('', inplace=True)\n",
    "df = df.reset_index()  # make sure indexes pair with number of rows\n",
    "\n",
    "for index, row in tqdm(df.iterrows(),bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}',total=len(df)):\n",
    "# add the feature to the array if it has not been added yet case insensitive\n",
    "    if row['feature'] not in arrayOfWords:\n",
    "        arrayOfWords.append(row['feature'])\n",
    "    # 1132\n",
    "vectorizer = TfidfVectorizer(stop_words={'english'})\n",
    "X = vectorizer.fit_transform(arrayOfWords)\n",
    "print(len(arrayOfWords))\n",
    "print(X.shape)\n",
    "x=X;\n",
    "model = KMeans(n_clusters=1132, init='k-means++', max_iter=200, n_init=10)\n",
    "model.fit(X)\n",
    "joblib.dump(model, 'model.pkl')\n",
    "score = silhouette_score(X, model.labels_, metric='euclidean')\n",
    "print(\"Silhouette score: {:.2f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/habib/Desktop/aait/ultimate_feed_nlp/bulk_generate_feature.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/bulk_generate_feature.ipynb#ch0000013?line=4'>5</a>\u001b[0m clusters\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(\u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(arrayOfWords,model\u001b[39m.\u001b[39mlabels_)),columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/bulk_generate_feature.ipynb#ch0000013?line=5'>6</a>\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(Y)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/bulk_generate_feature.ipynb#ch0000013?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(clusters\u001b[39m.\u001b[39mloc[clusters[\u001b[39m'\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m  np\u001b[39m.\u001b[39marray(np\u001b[39m.\u001b[39munique(labels), dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m)[prediction]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "vectorizer2=joblib.load('vectorizer.pkl')\n",
    "# print(model.cluster_centers_)\n",
    "Y = vectorizer2.transform([\"product\"])\n",
    "clusters=pd.DataFrame(list(zip(arrayOfWords,model.labels_)),columns=['title','cluster'])\n",
    "prediction = model.predict(Y)\n",
    "print(clusters.loc[clusters['cluster'] ==  np.array(np.unique(model.labels_), dtype=object)[prediction]])\n",
    "# print(model);\n",
    "# print(prediction)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
