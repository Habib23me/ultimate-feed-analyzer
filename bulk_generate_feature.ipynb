{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bd13a62c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.cluster import KMeans\n",
                "from tqdm import tqdm\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib as joblib\n",
                "import csv\n",
                "from sklearn.metrics import silhouette_score\n",
                "from services.database import ClusterFeatureDatabaseService"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dec5b4f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "def dataLoader(path):\n",
                "    data = pd.read_csv(path,encoding = \"ISO-8859-1\")\n",
                "    return data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "047dcc8e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def describe_cluster(words_list,model):\n",
                "    labels=model.labels_\n",
                "    clusters=pd.DataFrame(list(zip(words_list,labels)),columns=['title','cluster'])\n",
                "    u_labels =  np.array(np.unique(labels), dtype=object)\n",
                "    pd.options.display.max_rows = 4000   \n",
                "    for i in u_labels:\n",
                "      print(i)\n",
                "      print(clusters.loc[clusters['cluster'] == i])\n",
                "      print('\\n')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c08f8efc",
            "metadata": {},
            "outputs": [],
            "source": [
                "def cluster_text(text,k):\n",
                "    vectorizer = TfidfVectorizer(stop_words={'english'})\n",
                "    X = vectorizer.fit_transform(text)\n",
                "    model = KMeans(n_clusters=k, init='k-means++', max_iter=200, n_init=10)\n",
                "    model.fit(X)\n",
                "    joblib.dump(model, 'model.pkl')\n",
                "    score = silhouette_score(X, model.labels_, metric='euclidean')\n",
                "    print(\"Silhouette score: {:.2f}\".format(score))\n",
                "    # describe_cluster(text,model)\n",
                "    \n",
                "    return model\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1aeeb57c",
            "metadata": {},
            "outputs": [],
            "source": [
                "arrayOfWords=[];\n",
                "def groupDataSet(df):\n",
                "    df.fillna('', inplace=True)\n",
                "    df = df.reset_index()  # make sure indexes pair with number of rows\n",
                "  \n",
                "    for index, row in tqdm(df.iterrows(),bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}',total=len(df)):\n",
                "       # add the feature to the array if it has not been added yet case insensitive\n",
                "         if row['feature'] not in arrayOfWords:\n",
                "            arrayOfWords.append(row['feature'])\n",
                "            # 1132\n",
                "    return cluster_text(arrayOfWords,1132);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8c346301",
            "metadata": {},
            "outputs": [],
            "source": [
                "def predictCluster(text:str):\n",
                "    # load the model from disk\n",
                "    model = joblib.load('model.pkl')\n",
                "    # make predictions on the text\n",
                "    vectorizer = TfidfVectorizer(stop_words={'english'})\n",
                "    # predict clust of text using the model\n",
                "    X = vectorizer.fit_transform([text])\n",
                "    return model.predict(X)\n",
                "    \n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0e31004f",
            "metadata": {},
            "outputs": [],
            "source": [
                "data=dataLoader(\"data/final_features.csv\")\n",
                "data.head()\n",
                "model=groupDataSet(data)\n",
                "# data=predictCluster(\"Head\")\n",
                "# print(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f4bc0ac5",
            "metadata": {},
            "outputs": [],
            "source": [
                "def write_to_csv(datas, path):\n",
                "    with open(path, 'w') as f:\n",
                "        writer = csv.writer(f)\n",
                "        for i in range(0,len(datas)):\n",
                "            data=datas[i]\n",
                "            writer.writerow([i,','.join(data)])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2a88c830",
            "metadata": {},
            "outputs": [],
            "source": [
                "out = []\n",
                "for i in range(0,max(model.labels_)+1):\n",
                "    out.append([])\n",
                "\n",
                "for i in range(0,len(arrayOfWords)):\n",
                "    out[model.labels_[i]].append(arrayOfWords[i])\n",
                "for i in range(0,len(out)):\n",
                "    for word in out[i]:\n",
                "        ClusterFeatureDatabaseService().put({\n",
                "            \"cluster\":i,\n",
                "            \"feature\":word,\n",
                "            },\n",
                "        )\n",
                "\n",
                "print(out)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d85a7779",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "35b6ecf4",
            "metadata": {},
            "outputs": [],
            "source": [
                "cfs = ClusterFeatureDatabaseService().get_all()\n",
                "for cf in cfs:\n",
                "    print(cf)\n",
                "    print(cf['cluster'],cf['feature']) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2be694fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "cfs[0]"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
        },
        "kernelspec": {
            "display_name": "Python 3.8.9 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.9"
        },
        "vscode": {
            "interpreter": {
                "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
