{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#     Sum_of_squared_distances = []\n",
    "#     K = range(2,100)\n",
    "#     for k in K:\n",
    "#        km = KMeans(n_clusters=k, max_iter=200, n_init=10)\n",
    "#        km = km.fit(X)\n",
    "#        Sum_of_squared_distances.append(km.inertia_)\n",
    "#     plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "#     plt.xlabel('k')\n",
    "#     plt.ylabel('Sum_of_squared_distances')\n",
    "#     plt.title('Elbow Method For Optimal k')\n",
    "#     plt.show()\n",
    "\n",
    "    # print('How many clusters do you want to use?')\n",
    "    # true_k = int(input())\n",
    "    # predict which cluster newWord belongs to\n",
    "    # newWord_cluster = model.predict(vectorizer.transform([newWord]))\n",
    "#     import numpy as np\n",
    "# from sklearn.cluster import AffinityPropagation\n",
    "# import distance\n",
    "\n",
    "# def analyse_1(data):\n",
    "#     words = np.asarray(data) #So that indexing with a list will work\n",
    "#     lev_similarity = -1*np.array([[distance.levenshtein(w1,w2) for w1 in words] for w2 in words])\n",
    "\n",
    "#     affprop = AffinityPropagation(affinity=\"precomputed\", damping=0.5)\n",
    "#     affprop.fit(lev_similarity)\n",
    "#     for cluster_id in np.unique(affprop.labels_):\n",
    "#         exemplar = words[affprop.cluster_centers_indices_[cluster_id]]\n",
    "#         cluster = np.unique(words[np.nonzero(affprop.labels_==cluster_id)])\n",
    "#         cluster_str = \", \".join(cluster)\n",
    "#         print(\" - *%s:* %s\" % (exemplar, cluster_str))\n",
    "    \n",
    "# import nltk\n",
    "# import pandas\n",
    "# import pprint\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn import cluster\n",
    "# from sklearn import metrics\n",
    "# from gensim.models import Word2Vec\n",
    "# from nltk.cluster import KMeansClusterer\n",
    "# from sklearn.metrics import adjusted_rand_score\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.decomposition import NMF\n",
    "\n",
    "# def cluster_word_to_evac(word_list):\n",
    "#     min_count = 2\n",
    "#     size = 500\n",
    "#     window = 4\n",
    "\n",
    "#     model = Word2Vec(word_list, min_count=min_count, vector_size=size, window=window)\n",
    "#     X = np.asarray(model.wv.vectors)\n",
    "# #     labels = np.asarray(model.wv.index_to_key) \n",
    "# #     X = model[model.wv.index_to_key]\n",
    "\n",
    "#     print(len(X))\n",
    "\n",
    "#     clusters_number = 26\n",
    "    # kclusterer = KMeansClusterer(clusters_number,  distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "\n",
    "    # assigned_clusters = kclusterer.cluster(X, assign_clusters=True)\n",
    "\n",
    "    # words = list(model.wv.index_to_key)\n",
    "    # for i, word in enumerate(words):  \n",
    "    #     print (word + \":\" + str(assigned_clusters[i]))\n",
    "\n",
    "    # kmeans = cluster.KMeans(n_clusters = clusters_number)\n",
    "    # kmeans.fit(X)\n",
    "\n",
    "    # labels = kmeans.labels_\n",
    "    # centroids = kmeans.cluster_centers_\n",
    "\n",
    "    # clusters = {}\n",
    "    # score = silhouette_score(X, labels, metric='euclidean')\n",
    "\n",
    "    # print('Silhouetter Score: %.3f' % score)\n",
    "    # for commentaires, label in zip(word_list, labels):\n",
    "    #     try:\n",
    "    #         clusters[str(label)].append(commentaires)\n",
    "    #     except:\n",
    "    #        clusters[str(label)] = [commentaires]\n",
    "    # pprint.pprint(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from services.database import ActivityClusterDatabaseService,ActivityUserDatabaseService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Database Service\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'activityId': 'string', 'userId': 'string', 'score': 1}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ActivityClusterDatabaseService().get_all()\n",
    "ActivityUserDatabaseService().get_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'csr_matrix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb#ch0000003?line=8'>9</a>\u001b[0m     modelib\u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodel.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb#ch0000003?line=9'>10</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m modelib\u001b[39m.\u001b[39mpredict([X])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb#ch0000003?line=11'>12</a>\u001b[0m predictCluster(\u001b[39m\"\u001b[39;49m\u001b[39mhello\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb Cell 4'\u001b[0m in \u001b[0;36mpredictCluster\u001b[0;34m(feature)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb#ch0000003?line=7'>8</a>\u001b[0m X \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform([feature])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb#ch0000003?line=8'>9</a>\u001b[0m modelib\u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mmodel.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/habib/Desktop/aait/ultimate_feed_nlp/scratchpad.ipynb#ch0000003?line=9'>10</a>\u001b[0m \u001b[39mreturn\u001b[39;00m modelib\u001b[39m.\u001b[39;49mpredict([X])\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py:1330\u001b[0m, in \u001b[0;36mKMeans.predict\u001b[0;34m(self, X, sample_weight)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1307'>1308</a>\u001b[0m \u001b[39m\"\"\"Predict the closest cluster each sample in X belongs to.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1308'>1309</a>\u001b[0m \n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1309'>1310</a>\u001b[0m \u001b[39mIn the vector quantization literature, `cluster_centers_` is called\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1325'>1326</a>\u001b[0m \u001b[39m    Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1326'>1327</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1327'>1328</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1329'>1330</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_test_data(X)\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1330'>1331</a>\u001b[0m x_squared_norms \u001b[39m=\u001b[39m row_norms(X, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1331'>1332</a>\u001b[0m sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py:1007\u001b[0m, in \u001b[0;36mKMeans._check_test_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1005'>1006</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_test_data\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m-> <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1006'>1007</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1007'>1008</a>\u001b[0m         X,\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1008'>1009</a>\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1009'>1010</a>\u001b[0m         reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1010'>1011</a>\u001b[0m         dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1011'>1012</a>\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1012'>1013</a>\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1013'>1014</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/cluster/_kmeans.py?line=1014'>1015</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m X\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/base.py?line=563'>564</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/base.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/base.py?line=565'>566</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/base.py?line=566'>567</a>\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/base.py?line=567'>568</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py?line=743'>744</a>\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py?line=744'>745</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py?line=745'>746</a>\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py?line=746'>747</a>\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py?line=747'>748</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py?line=748'>749</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    <a href='file:///Users/habib/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py?line=749'>750</a>\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from services.cluster_features import predictCluster\n",
    "import joblib;\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def predictCluster(feature:str):\n",
    "    vectorizer = TfidfVectorizer(stop_words={'english'})\n",
    "    # # predict clust of text using the model\n",
    "    X = vectorizer.fit_transform([feature])\n",
    "    modelib= joblib.load('model.pkl')\n",
    "    return modelib.predict(X)\n",
    "\n",
    "predictCluster(\"hello\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
